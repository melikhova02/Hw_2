---
title: "Лабораторная_2"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
  word_document: default
---
### Оценка точности модели с дискретной зависимой переменной (Y)

В данной задаче выполняются следующие пункты:   
  
* расчет матрицы неточностей;  
* расчет показателей качества модели по матрице неточностей;  
* изучение наивного байесовского классификатора;
* изучение метода kNN (k ближайших соседей).

*Модели*: наивный байесовский классификатор, kNN (метод k ближайших соседей).  
*Данные*: сгенерированные.

## 1.Генерация данных.
```{r generate-data}
library('mlbench')
library('class')
library('car')
library('class')
library('e1071')
library('MASS')
my.seed <- 12345

# Данные примера 3 .............................................................
n <- 100               # наблюдений всего
train.percent <- 0.85  # доля обучающей выборки

# x-ы -- двумерные нормальные случайные величины
set.seed(my.seed)
class.0 <- mvrnorm(45, mu = c(22, 7), 
                   Sigma = matrix(c(4.5^2, 0, 0, 18^2), 2, 2, byrow = T))

set.seed(my.seed + 1)
class.1 <- mvrnorm(55, mu = c(25, 31), 
                   Sigma = matrix(c(2.5^2, 0, 0, 25^2), 2, 2, byrow = T))

# записываем x-ы в единые векторы (объединяем классы 0 и 1)
x1 <- c(class.0[, 1], class.1[, 1])
x2 <- c(class.0[, 2], class.1[, 2])

# фактические классы Y
y <- c(rep(0, nrow(class.0)), rep(1, nrow(class.1)))

# классы для наблюдений сетки
rules <- function(x1, x2){
  ifelse(x2 < 1.6*x1 + 19, 0, 1)
}
set.seed(my.seed)
inTrain <- sample(seq_along(x1), train.percent * n)
x1.train <- x1[inTrain]
x2.train <- x2[inTrain]
x1.test <- x1[-inTrain]
x2.test <- x2[-inTrain]

# используем истинные правила, чтобы присвоить фактические классы
y.train <- y[inTrain]
y.test <- y[-inTrain]

# фрейм с обучающей выборкой
df.train.1 <- data.frame(x1 = x1.train, x2 = x2.train, y = y.train)
# фрейм с тестовой выборкой
df.test.1 <- data.frame(x1 = x1.test, x2 = x2.test)
```

## 2.Отображение обучающей выборки на графике.
Нарисуем обучающую выборку на графике. Сеткой точек показаны области классов, соответствующие истинным дискриминирующим правилам.
```{r plot_1}
# для сетки (истинных областей классов): целочисленные значения x1, x2
x1.grid <- rep(seq(floor(min(x1)), ceiling(max(x1)), by = 1),
               ceiling(max(x2)) - floor(min(x2)) + 1)
x2.grid <- rep(seq(floor(min(x2)), ceiling(max(x2)), by = 1),
               each = ceiling(max(x1)) - floor(min(x1)) + 1)

# классы для наблюдений сетки
y.grid <- rules(x1.grid,x2.grid) 

# фрейм для сетки
df.grid.1 <- data.frame(x1 = x1.grid, x2 = x2.grid, y = y.grid)

# цвета для графиков
cls <- c('blue', 'orange')
cls.t <- c(rgb(0, 0, 1, alpha = 0.5), rgb(1,0.5,0, alpha = 0.5))

# график истинных классов
plot(df.grid.1$x1, df.grid.1$x2, 
     pch = ' ',col = cls[df.grid.1[, 'y'] + 0],
     xlab = 'X1', ylab = 'Y1',
     main = 'Обучающая выборка, факт')
# точки фактических наблюдений
points(df.train.1$x1,df.train.1$x2, 
       pch = 21, bg = cls.t[df.train.1[, 'y'] + 1], 
       col = cls.t[df.train.1[, 'y'] + 1])
```

## 3.Байесовский классификатор 
Обучим модель наивного байесовского классификатора и оценим её точность (верность) на обучающей выборке.
```{r Bayes_train}
# строим модель
nb <- naiveBayes(y ~ ., data = df.train.1)
# получаем модельные значения на обучающей выборке как классы
y.nb.train <- ifelse(predict(nb, df.train.1[, -3],
                             type = 'raw')[,2] > 0.5, 1, 0) #выбрасываем третий столбец у

# график истинных классов
plot(df.grid.1$x1, df.grid.1$x2, 
       pch = ' ',col = cls[df.grid.1[, 'y'] + 1], 
     xlab = 'X1', ylab = 'Y1',
     main = 'Обучающая выборка, модель naiveBayes')
# точки наблюдений, предсказанных по модели
points(df.train.1$x1, df.train.1$x2, 
       pch = 21, bg = cls.t[y.nb.train + 1], 
       col = cls.t[y.nb.train + 1])

# матрица неточностей на обучающей выборке
tbl <- table(y.train, y.nb.train)
tbl

# точность, или верность (Accuracy)
Acc <- sum(diag(tbl)) / sum(tbl)
Acc
```

Байесовская решающая граница не моделирует разрыв жёлтого класса синим.Сделаем прогноз классов Y на тестовую выборку и оценим точность модели. Как можно убедиться, точность на тестовой оказывается ниже, чем на обучающей выборке. Учитывая, как ведёт себя классификатор на обучающей выборке, такой модели доверять не стоит.

```{r Bayes_test}
# прогноз на тестовую выборку
y.nb.test <- ifelse(predict(nb, df.test.1[, -3],
                            type = 'raw')[, 2] > 0.5, 1, 0)

# матрица неточностей на тестовой выборке
tbl <-table(y.test, y.nb.test) 
tbl

# точность, или верность (Accuracy)
Acc <- sum(diag(tbl)) / sum(tbl)
Acc
```
## 4.Метод kNN.
Построим модель kNN. Это “ленивый” классификатор, ему не требуется предварительное обучение. Этот непараметрический метод хорошо работает с линейно неразделимыми классами. Зададим k=3.

```{r knn_train}
# строим модель и делаем прогноз
y.knn.train <- knn(train = scale(df.train.1[, -3]),
                   test = scale(df.train.1[, -3]),
                   cl=df.train.1$y, k = 3)

# график истинных классов
plot(df.grid.1$x1, df.grid.1$x2,
      pch = ' ',col = cls[df.grid.1[, 'y'] + 1],
     xlab = 'X1', ylab = 'Y1',
     main = 'Обучающая выборка, модель kNN')
# точки наблюдений, предсказанных по модели
points(df.train.1$x1, df.train.1$x2,
       pch = 21, bg = cls.t[as.numeric(y.knn.train)], 
       col = cls.t[as.numeric(y.knn.train)])

# матрица неточностей на обучающей выборке
tbl <- table(y.train, y.knn.train)
tbl

# точность (Accuracy)
Acc <- sum(diag(tbl)) / sum(tbl)
Acc
```

Можно видеть, что классификация обучающей выборки методом kNN близка к фактическим классам наблюдений.
Оценим также точность модели на тестовой выборке.

```{r knn}
# прогноз на тестовую выборку
y.knn.test <- knn(train = scale(df.train.1[, -3]),
                  test = scale(df.test.1[, -3]),
                  cl=df.train.1$y, k = 3)

# матрица неточностей на тестовой выборке
tbl <- table(y.test, y.knn.test)
tbl

# точность (Accuracy)
Acc <- sum(diag(tbl)) / sum(tbl)
Acc
```
Модель kNN оказалась точнее на этих данных, чем модель наивного байесовского классификатора. Рассчитаем характеристики качества и ошибки по матрице неточностей последней, наилучшей модели.

## 5.Характеристики качества и ошибки.
```{r parameters}
TPR <- tbl[2, 2] / (tbl[2, 2] + tbl[2, 1])
SPC <- tbl[1, 1] / (tbl[1, 2] + tbl[1, 1])
PPV <- tbl[2, 2] / (tbl[2, 2] + tbl[1, 2])
NPV <- tbl[1, 1] / (tbl[2, 1] + tbl[1, 1])
FNR <- 1 - TPR
FPR <- 1 - SPC
FDR <- 1 - PPV
MCC <- (tbl[2, 2] * tbl[1, 1] - tbl[1, 2] * tbl[2, 1])/ 
        sqrt((tbl[2, 2]+tbl[1, 2])*(tbl[2, 2]+tbl[2, 1])*(tbl[1, 1]+tbl[1, 2])*(tbl[1, 1]+tbl[2, 1]))
names <- c("TPR","SPC","PPV","NPV","FNR","FPR","FDR","MCC")
numbers <- c(TPR,SPC,PPV,NPV,FNR,FPR,FDR,MCC)
frame <- data.frame(Характеристики = names, Значения = numbers)
frame
```